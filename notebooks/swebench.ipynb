{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d69aea4-adf2-4900-afbb-2e8d8a0bb9ac",
   "metadata": {},
   "source": [
    "# Solve SWE-bench issues\n",
    "\n",
    "This notebook demonstrates how to solve issues in the [SWE-bench dataset](https://www.swebench.com/) using Moatless tools. The philosophy behind Moatless tools is that at the current level of LLMs, reasoning is not the most important aspect, but rather providing the LLM with the correct context in prompts and handling responses in an appropriate manner. This can be resolved by focusing on building good tooling that an agent can use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4440708-e5f5-4176-8d00-5507cff40765",
   "metadata": {},
   "source": [
    "## SWE-bench\n",
    "SWE-bench is a benchmark for evaluating large language models on real world software issues collected from GitHub. Given a codebase and an issue, a language model is tasked with generating a patch that resolves the described problem.\n",
    "\n",
    "To execute a specific instance of the SWE-bench, specify the `instance_id` parameter. The dataset will then be downloaded, and the instance will be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fba48c-114f-4c20-abe0-360d251d8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Problem statement\n",
       "Lexer \"python3\" in --pastebin feature causes HTTP errors\n",
       "The `--pastebin` option currently submits the output of `pytest` to `bpaste.net` using `lexer=python3`: https://github.com/pytest-dev/pytest/blob/d47b9d04d4cf824150caef46c9c888779c1b3f58/src/_pytest/pastebin.py#L68-L73\r\n",
       "\r\n",
       "For some `contents`, this will raise a \"HTTP Error 400: Bad Request\".\r\n",
       "\r\n",
       "As an example:\r\n",
       "~~~\r\n",
       ">>> from urllib.request import urlopen\r\n",
       ">>> with open(\"data.txt\", \"rb\") as in_fh:\r\n",
       "...     data = in_fh.read()\r\n",
       ">>> url = \"https://bpaste.net\"\r\n",
       ">>> urlopen(url, data=data)\r\n",
       "HTTPError: Bad Request\r\n",
       "~~~\r\n",
       "with the attached [data.txt](https://github.com/pytest-dev/pytest/files/3561212/data.txt).\r\n",
       "\r\n",
       "This is the underlying cause for the problems mentioned in #5764.\r\n",
       "\r\n",
       "The call goes through fine if `lexer` is changed from `python3` to `text`. This would seem like the right thing to do in any case: the console output of a `pytest` run that is being uploaded is not Python code, but arbitrary text.\r\n",
       "\n",
       "\n",
       "\n",
       "### Expected patch\n",
       "```diff\n",
       "diff --git a/src/_pytest/pastebin.py b/src/_pytest/pastebin.py\n",
       "--- a/src/_pytest/pastebin.py\n",
       "+++ b/src/_pytest/pastebin.py\n",
       "@@ -65,7 +65,7 @@ def create_new_paste(contents):\n",
       "     from urllib.request import urlopen\n",
       "     from urllib.parse import urlencode\n",
       " \n",
       "-    params = {\"code\": contents, \"lexer\": \"python3\", \"expiry\": \"1week\"}\n",
       "+    params = {\"code\": contents, \"lexer\": \"text\", \"expiry\": \"1week\"}\n",
       "     url = \"https://bpaste.net\"\n",
       "     try:\n",
       "         response = (\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from benchmark import swebench\n",
    "\n",
    "data_dir = None # Set this to store the dataset to disk\n",
    "\n",
    "instance_id = 'pytest-dev__pytest-5808'\n",
    "instance_data = swebench.get_instance(instance_id, dataset_name='princeton-nlp/SWE-bench', split='test', data_dir=data_dir)\n",
    "\n",
    "swebench.display_problem_statement(instance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb532943-81c1-47ad-bbb5-6a4a1bc5208e",
   "metadata": {},
   "source": [
    "## Index the code base\n",
    "The code is cloned from GitHub and subsequently indexed in a vector store. This enables semantic searches within the codebase. The idea is that this serves as the entry point where an initial, broad search is conducted to identify potentially relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8901b45-a3ba-4717-9816-2c578b733abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo 'git@github.com:pytest-dev/pytest.git' already exists in '/tmp/repos/pytest-dev_pytest'\n",
      "HEAD is now at 404cf0c87 Merge pull request #5764 from goerz/pastebin\n"
     ]
    }
   ],
   "source": [
    "from moatless.utils.repo import setup_github_repo\n",
    "\n",
    "path = setup_github_repo(repo=instance_data['repo'], base_commit=instance_data['base_commit'], base_dir='/tmp/repos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a110f-d63c-478b-a4bb-de870bd185fe",
   "metadata": {},
   "source": [
    "### Index the code base\n",
    "Indexing is done using Llama index. During the indexing phase, the code is divided into relevant chunks. This is accomplished with a special code splitter, `EpicSplitter`, that segments code files at the function and class level, retaining contextual information from parent classes/functions.\n",
    "\n",
    "Currently, a custom vector store, `SimpleFaissVectorStore`, which is a hybrid of Faiss and SimpleVectorStore in LlamaIndex, is being used. This can easily be replaced with other implementations available in Llama index.\n",
    "\n",
    "Currently, the pipeline is configured to use OpenAI's embedding model `text-embedding-3-small`, so the environment variable `OPENAI_API_KEY` must be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8948da8a-a622-45f5-a479-92cba02f181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ac79d75b1b40d9973217d1d1304a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e27c08972c4c6090cb3773e92a028f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 881 vectors with 235057 tokens\n"
     ]
    }
   ],
   "source": [
    "from moatless.ingestion import CodeBaseIngestionPipeline\n",
    "from moatless.splitters.epic_split import CommentStrategy, EpicSplitter\n",
    "from moatless.store.simple_faiss import SimpleFaissVectorStore\n",
    "\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "persist_dir = None # Set this to persist and load data from disk \n",
    "\n",
    "vector_store = None\n",
    "docstore = None\n",
    "\n",
    "if persist_dir:\n",
    "    try:\n",
    "        vector_store = SimpleFaissVectorStore.from_persist_dir(persist_dir=persist_dir)\n",
    "        docstore = SimpleDocumentStore.from_persist_dir(persist_dir=persist_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load stores from {persist_dir}: {e}\") \n",
    "\n",
    "if not vector_store:\n",
    "    vector_store = SimpleFaissVectorStore.from_defaults()\n",
    "\n",
    "if not docstore:\n",
    "    docstore = SimpleDocumentStore()\n",
    "\n",
    "embedding = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "ingestion_pipeline = CodeBaseIngestionPipeline(\n",
    "    path=path,\n",
    "    vector_store=vector_store,\n",
    "    docstore=docstore,\n",
    "    splitter=EpicSplitter(min_chunk_size=100, chunk_size=750, language=\"python\", comment_strategy=CommentStrategy.ASSOCIATE),\n",
    "    embed_model=embedding\n",
    ")\n",
    "vectors, tokens = ingestion_pipeline.run()\n",
    "print(f\"Indexed {vectors} vectors with {tokens} tokens\")\n",
    "\n",
    "if persist_dir:\n",
    "    ingestion_pipeline.persist(persist_dir=persist_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd088e-f984-462a-ac1f-a7c21e774c03",
   "metadata": {},
   "source": [
    "## Retrieve files\n",
    "Code snippets are retrieved by identifying those snippets that are semantically similar to the problem statement specified in SWE-bench. Code snippets are retrieved until the context reaches 200k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b249a4-9537-47c6-9695-6eae335339c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='background-color: #f2f2f2; padding: 10px; border-left: 6px solid #ffcc00; margin-bottom: 10px;'>All expected patch files is referred to in the retrieved code snippets.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_40f78 .col0 {\n",
       "  width: 120px;\n",
       "  max-width: 350px;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       "#T_40f78 .col1 {\n",
       "  width: 120px;\n",
       "  max-width: 350px;\n",
       "}\n",
       "#T_40f78 .col2 {\n",
       "  width: 80px;\n",
       "  max-width: 80px;\n",
       "}\n",
       "#T_40f78 .col3 {\n",
       "  width: 80px;\n",
       "  max-width: 80px;\n",
       "}\n",
       "#T_40f78 .col4 {\n",
       "  width: 80px;\n",
       "  max-width: 80px;\n",
       "}\n",
       "#T_40f78_row0_col0, #T_40f78_row0_col1, #T_40f78_row0_col2, #T_40f78_row0_col3, #T_40f78_row0_col4, #T_40f78_row1_col0, #T_40f78_row1_col1, #T_40f78_row1_col2, #T_40f78_row1_col3, #T_40f78_row1_col4, #T_40f78_row3_col0, #T_40f78_row3_col1, #T_40f78_row3_col2, #T_40f78_row3_col3, #T_40f78_row3_col4 {\n",
       "  background-color: #C8E6C9;\n",
       "}\n",
       "#T_40f78_row2_col0, #T_40f78_row2_col1, #T_40f78_row2_col2, #T_40f78_row2_col3, #T_40f78_row2_col4 {\n",
       "  background-color: #4CAF50;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_40f78\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_40f78_level0_col0\" class=\"col_heading level0 col0\" >File</th>\n",
       "      <th id=\"T_40f78_level0_col1\" class=\"col_heading level0 col1\" >Block</th>\n",
       "      <th id=\"T_40f78_level0_col2\" class=\"col_heading level0 col2\" >Start line</th>\n",
       "      <th id=\"T_40f78_level0_col3\" class=\"col_heading level0 col3\" >End line</th>\n",
       "      <th id=\"T_40f78_level0_col4\" class=\"col_heading level0 col4\" >Context length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_40f78_row0_col0\" class=\"data row0 col0\" >src/_pytest/pastebin.py</td>\n",
       "      <td id=\"T_40f78_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_40f78_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_40f78_row0_col3\" class=\"data row0 col3\" >38</td>\n",
       "      <td id=\"T_40f78_row0_col4\" class=\"data row0 col4\" >268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_40f78_row1_col0\" class=\"data row1 col0\" >src/_pytest/pastebin.py</td>\n",
       "      <td id=\"T_40f78_row1_col1\" class=\"data row1 col1\" >pytest_terminal_summary</td>\n",
       "      <td id=\"T_40f78_row1_col2\" class=\"data row1 col2\" >83</td>\n",
       "      <td id=\"T_40f78_row1_col3\" class=\"data row1 col3\" >104</td>\n",
       "      <td id=\"T_40f78_row1_col4\" class=\"data row1 col4\" >449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_40f78_row2_col0\" class=\"data row2 col0\" >src/_pytest/pastebin.py</td>\n",
       "      <td id=\"T_40f78_row2_col1\" class=\"data row2 col1\" >create_new_paste</td>\n",
       "      <td id=\"T_40f78_row2_col2\" class=\"data row2 col2\" >57</td>\n",
       "      <td id=\"T_40f78_row2_col3\" class=\"data row2 col3\" >80</td>\n",
       "      <td id=\"T_40f78_row2_col4\" class=\"data row2 col4\" >660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_40f78_row3_col0\" class=\"data row3 col0\" >src/_pytest/pastebin.py</td>\n",
       "      <td id=\"T_40f78_row3_col1\" class=\"data row3 col1\" >pytest_unconfigure</td>\n",
       "      <td id=\"T_40f78_row3_col2\" class=\"data row3 col2\" >41</td>\n",
       "      <td id=\"T_40f78_row3_col3\" class=\"data row3 col3\" >54</td>\n",
       "      <td id=\"T_40f78_row3_col4\" class=\"data row3 col4\" >805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_40f78_row4_col0\" class=\"data row4 col0\" >src/pytest.py</td>\n",
       "      <td id=\"T_40f78_row4_col1\" class=\"data row4 col1\" >1</td>\n",
       "      <td id=\"T_40f78_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "      <td id=\"T_40f78_row4_col3\" class=\"data row4 col3\" >107</td>\n",
       "      <td id=\"T_40f78_row4_col4\" class=\"data row4 col4\" >1513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_40f78_row5_col0\" class=\"data row5 col0\" >src/_pytest/faulthandler.py</td>\n",
       "      <td id=\"T_40f78_row5_col1\" class=\"data row5 col1\" >io</td>\n",
       "      <td id=\"T_40f78_row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "      <td id=\"T_40f78_row5_col3\" class=\"data row5 col3\" >36</td>\n",
       "      <td id=\"T_40f78_row5_col4\" class=\"data row5 col4\" >1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_40f78_row6_col0\" class=\"data row6 col0\" >src/_pytest/pytester.py</td>\n",
       "      <td id=\"T_40f78_row6_col1\" class=\"data row6 col1\" >pytest_addoption</td>\n",
       "      <td id=\"T_40f78_row6_col2\" class=\"data row6 col2\" >32</td>\n",
       "      <td id=\"T_40f78_row6_col3\" class=\"data row6 col3\" >54</td>\n",
       "      <td id=\"T_40f78_row6_col4\" class=\"data row6 col4\" >1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_40f78_row7_col0\" class=\"data row7 col0\" >src/_pytest/python.py</td>\n",
       "      <td id=\"T_40f78_row7_col1\" class=\"data row7 col1\" >pytest_addoption</td>\n",
       "      <td id=\"T_40f78_row7_col2\" class=\"data row7 col2\" >56</td>\n",
       "      <td id=\"T_40f78_row7_col3\" class=\"data row7 col3\" >108</td>\n",
       "      <td id=\"T_40f78_row7_col4\" class=\"data row7 col4\" >2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_40f78_row8_col0\" class=\"data row8 col0\" >src/_pytest/skipping.py</td>\n",
       "      <td id=\"T_40f78_row8_col1\" class=\"data row8 col1\" >pytest_configure</td>\n",
       "      <td id=\"T_40f78_row8_col2\" class=\"data row8 col2\" >28</td>\n",
       "      <td id=\"T_40f78_row8_col3\" class=\"data row8 col3\" >65</td>\n",
       "      <td id=\"T_40f78_row8_col4\" class=\"data row8 col4\" >2623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_40f78_row9_col0\" class=\"data row9 col0\" >src/_pytest/python.py</td>\n",
       "      <td id=\"T_40f78_row9_col1\" class=\"data row9 col1\" >pytest_cmdline_main</td>\n",
       "      <td id=\"T_40f78_row9_col2\" class=\"data row9 col2\" >111</td>\n",
       "      <td id=\"T_40f78_row9_col3\" class=\"data row9 col3\" >129</td>\n",
       "      <td id=\"T_40f78_row9_col4\" class=\"data row9 col4\" >2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_40f78_row10_col0\" class=\"data row10 col0\" >src/_pytest/reports.py</td>\n",
       "      <td id=\"T_40f78_row10_col1\" class=\"data row10 col1\" >_report_unserialization_failure</td>\n",
       "      <td id=\"T_40f78_row10_col2\" class=\"data row10 col2\" >265</td>\n",
       "      <td id=\"T_40f78_row10_col3\" class=\"data row10 col3\" >274</td>\n",
       "      <td id=\"T_40f78_row10_col4\" class=\"data row10 col4\" >2933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_40f78_row11_col0\" class=\"data row11 col0\" >...</td>\n",
       "      <td id=\"T_40f78_row11_col1\" class=\"data row11 col1\" >...</td>\n",
       "      <td id=\"T_40f78_row11_col2\" class=\"data row11 col2\" >...</td>\n",
       "      <td id=\"T_40f78_row11_col3\" class=\"data row11 col3\" >...</td>\n",
       "      <td id=\"T_40f78_row11_col4\" class=\"data row11 col4\" >...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_40f78_row12_col0\" class=\"data row12 col0\" >...</td>\n",
       "      <td id=\"T_40f78_row12_col1\" class=\"data row12 col1\" >...</td>\n",
       "      <td id=\"T_40f78_row12_col2\" class=\"data row12 col2\" >...</td>\n",
       "      <td id=\"T_40f78_row12_col3\" class=\"data row12 col3\" >...</td>\n",
       "      <td id=\"T_40f78_row12_col4\" class=\"data row12 col4\" >...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_40f78_row13_col0\" class=\"data row13 col0\" >...</td>\n",
       "      <td id=\"T_40f78_row13_col1\" class=\"data row13 col1\" >...</td>\n",
       "      <td id=\"T_40f78_row13_col2\" class=\"data row13 col2\" >...</td>\n",
       "      <td id=\"T_40f78_row13_col3\" class=\"data row13 col3\" >...</td>\n",
       "      <td id=\"T_40f78_row13_col4\" class=\"data row13 col4\" >...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row749\" class=\"row_heading level0 row749\" >749</th>\n",
       "      <td id=\"T_40f78_row749_col0\" class=\"data row749 col0\" >src/_pytest/_code/code.py</td>\n",
       "      <td id=\"T_40f78_row749_col1\" class=\"data row749 col1\" >ExceptionInfo.match</td>\n",
       "      <td id=\"T_40f78_row749_col2\" class=\"data row749 col2\" >599</td>\n",
       "      <td id=\"T_40f78_row749_col3\" class=\"data row749 col3\" >610</td>\n",
       "      <td id=\"T_40f78_row749_col4\" class=\"data row749 col4\" >198526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row750\" class=\"row_heading level0 row750\" >750</th>\n",
       "      <td id=\"T_40f78_row750_col0\" class=\"data row750 col0\" >src/_pytest/capture.py</td>\n",
       "      <td id=\"T_40f78_row750_col1\" class=\"data row750 col1\" >CaptureManager.deactivate_fixture</td>\n",
       "      <td id=\"T_40f78_row750_col2\" class=\"data row750 col2\" >153</td>\n",
       "      <td id=\"T_40f78_row750_col3\" class=\"data row750 col3\" >238</td>\n",
       "      <td id=\"T_40f78_row750_col4\" class=\"data row750 col4\" >199098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row751\" class=\"row_heading level0 row751\" >751</th>\n",
       "      <td id=\"T_40f78_row751_col0\" class=\"data row751 col0\" >testing/python/collect.py</td>\n",
       "      <td id=\"T_40f78_row751_col1\" class=\"data row751 col1\" >TestSorting.test_allow_sane_sorting_for_decorators</td>\n",
       "      <td id=\"T_40f78_row751_col2\" class=\"data row751 col2\" >690</td>\n",
       "      <td id=\"T_40f78_row751_col3\" class=\"data row751 col3\" >710</td>\n",
       "      <td id=\"T_40f78_row751_col4\" class=\"data row751 col4\" >199231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row752\" class=\"row_heading level0 row752\" >752</th>\n",
       "      <td id=\"T_40f78_row752_col0\" class=\"data row752 col0\" >src/_pytest/fixtures.py</td>\n",
       "      <td id=\"T_40f78_row752_col1\" class=\"data row752 col1\" >FixtureManager._get_direct_parametrize_args</td>\n",
       "      <td id=\"T_40f78_row752_col2\" class=\"data row752 col2\" >1122</td>\n",
       "      <td id=\"T_40f78_row752_col3\" class=\"data row752 col3\" >1141</td>\n",
       "      <td id=\"T_40f78_row752_col4\" class=\"data row752 col4\" >199396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row753\" class=\"row_heading level0 row753\" >753</th>\n",
       "      <td id=\"T_40f78_row753_col0\" class=\"data row753 col0\" >src/_pytest/hookspec.py</td>\n",
       "      <td id=\"T_40f78_row753_col1\" class=\"data row753 col1\" >pytest_report_collectionfinish</td>\n",
       "      <td id=\"T_40f78_row753_col2\" class=\"data row753 col2\" >542</td>\n",
       "      <td id=\"T_40f78_row753_col3\" class=\"data row753 col3\" >553</td>\n",
       "      <td id=\"T_40f78_row753_col4\" class=\"data row753 col4\" >199506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_40f78_level0_row754\" class=\"row_heading level0 row754\" >754</th>\n",
       "      <td id=\"T_40f78_row754_col0\" class=\"data row754 col0\" >src/_pytest/junitxml.py</td>\n",
       "      <td id=\"T_40f78_row754_col1\" class=\"data row754 col1\" >_NodeReporter</td>\n",
       "      <td id=\"T_40f78_row754_col2\" class=\"data row754 col2\" >84</td>\n",
       "      <td id=\"T_40f78_row754_col3\" class=\"data row754 col3\" >116</td>\n",
       "      <td id=\"T_40f78_row754_col4\" class=\"data row754 col4\" >199713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ecbeac8fa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from moatless.retriever import CodeSnippetRetriever\n",
    "\n",
    "retriever = CodeSnippetRetriever(\n",
    "    vector_store=vector_store,\n",
    "    docstore=docstore,\n",
    "    embed_model=embedding,\n",
    "    max_context_tokens=200000\n",
    ")\n",
    "\n",
    "code_snippets = retriever.retrieve(query=instance_data['problem_statement'])\n",
    "\n",
    "swebench.display_code_snippets(instance_data, code_snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630a2e1-a613-4561-991b-2760f83dd7b3",
   "metadata": {},
   "source": [
    "## Select relevant files\n",
    "The retrieved code snippets are fed into an LLM, which selects the files that are most relevant based on the problem statement.\n",
    "\n",
    "In this step, Claude 3 Haiku is used, which means you need an Anthropic API Key set in the environment variable `ANTHROPIC_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e144a0-7aca-4922-b2c7-60bb790ba63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='background-color: #f2f2f2; padding: 10px; border-left: 6px solid #ffcc00; margin-bottom: 10px;'>All expected patch files was selected.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_648fd th {\n",
       "  font-size: 12pt;\n",
       "}\n",
       "#T_648fd td {\n",
       "  padding: 0px 10px;\n",
       "}\n",
       "#T_648fd .pandas-dataframe {\n",
       "  width: 100%;\n",
       "}\n",
       "#T_648fd_row0_col0, #T_648fd_row0_col1 {\n",
       "  background-color: #4CAF50;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_648fd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_648fd_level0_col0\" class=\"col_heading level0 col0\" >File</th>\n",
       "      <th id=\"T_648fd_level0_col1\" class=\"col_heading level0 col1\" >Context length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_648fd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_648fd_row0_col0\" class=\"data row0 col0\" >src/_pytest/pastebin.py</td>\n",
       "      <td id=\"T_648fd_row0_col1\" class=\"data row0 col1\" >806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_648fd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_648fd_row1_col0\" class=\"data row1 col0\" >src/_pytest/config/__init__.py</td>\n",
       "      <td id=\"T_648fd_row1_col1\" class=\"data row1 col1\" >3517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ecbeab39450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from moatless.selector import FileSelector\n",
    "\n",
    "file_selector = FileSelector(repo_path=path, model_name='claude-3-haiku-20240307', file_context_token_limit=50000)\n",
    "\n",
    "selector_response = file_selector.select_files(query=instance_data['problem_statement'], code_snippets=code_snippets)\n",
    "\n",
    "swebench.display_files(instance_data, selector_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbed747-781f-4a0f-979f-69c3f2870028",
   "metadata": {},
   "source": [
    "## Create development plan\n",
    "Before coding begins, it is planned out in smaller tasks to develop parts of the codebase separately. This involves defining \"code blocks\" that need to be updated, where a code block can be, for example, a class or a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da4599a3-3470-4a15-851a-64c59c437839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Thoughts\n",
       "\n",
       "> To address the issue with the `--pastebin` option causing HTTP errors due to the `lexer=python3` parameter, we need to update the `create_new_paste` function in `src/_pytest/pastebin.py` to use `lexer=text` instead. This change will ensure that the console output of a `pytest` run, which is arbitrary text and not Python code, is correctly submitted to the pastebin service without causing HTTP 400 errors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Planned tasks\n",
       "### Update src/_pytest/pastebin.py\n",
       "        \n",
       "Blocks to update: \n",
       "\n",
       " * `create_new_paste`\n",
       "\n",
       "#### Instructions\n",
       "Change the value of the 'lexer' key in the 'params' dictionary from 'python3' to 'text'. This modification ensures that the pastebin service correctly interprets the submitted content as text, avoiding HTTP 400 errors.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from moatless.planner import Planner\n",
    "\n",
    "planner = Planner(repo_path=path, model_name='gpt-4-0125-preview')\n",
    "\n",
    "file_paths = [file.file_path for file in selector_response.files]\n",
    "response = planner.plan_development(instructions=instance_data['problem_statement'], files=file_paths)\n",
    "\n",
    "swebench.display_plan(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974078f-19c5-4c0a-b9fa-c2e9e3b23883",
   "metadata": {},
   "source": [
    "## Write code\n",
    "Finally, the code can be written. This is done task by task. We do not use any diff tool; instead, we expect only small parts of the codebase to be updated and for the LLM to return the entire code for this smaller part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdb8c9d-a655-4143-9a08-1c64756df2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Updated src/_pytest/pastebin.py\n",
       "```diff\n",
       "--- /tmp/repos/pytest-dev_pytest/src/_pytest/pastebin.py\n",
       "+++ /tmp/repos/pytest-dev_pytest/src/_pytest/pastebin.py\n",
       "@@ -65,7 +65,7 @@\n",
       "     from urllib.request import urlopen\n",
       "     from urllib.parse import urlencode\n",
       " \n",
       "-    params = {\"code\": contents, \"lexer\": \"python3\", \"expiry\": \"1week\"}\n",
       "+    params = {\"code\": contents, \"lexer\": \"text\", \"expiry\": \"1week\"}\n",
       "     url = \"https://bpaste.net\"\n",
       "     try:\n",
       "         response = (\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from moatless.coder import Coder\n",
    "\n",
    "coder = Coder(repo_path=path, model_name='gpt-4-0125-preview')\n",
    "\n",
    "for task in response.tasks:\n",
    "    response = coder.write_code(main_objective=instance_data['problem_statement'],\n",
    "                                instructions=task.instructions,\n",
    "                                file_path=task.file_path,\n",
    "                                block_paths=task.block_paths)\n",
    "\n",
    "    swebench.display_code_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18daf1f-30f6-42d9-a790-f3f8dc051cf0",
   "metadata": {},
   "source": [
    "## Verify the change\n",
    "Verify if the code is as expected by comparing it with the patch in SWE-bench. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485d1a41-be37-4142-80b1-2f9192a08046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Expected patch\n",
       "```diff\n",
       "diff --git a/src/_pytest/pastebin.py b/src/_pytest/pastebin.py\n",
       "--- a/src/_pytest/pastebin.py\n",
       "+++ b/src/_pytest/pastebin.py\n",
       "@@ -65,7 +65,7 @@ def create_new_paste(contents):\n",
       "     from urllib.request import urlopen\n",
       "     from urllib.parse import urlencode\n",
       " \n",
       "-    params = {\"code\": contents, \"lexer\": \"python3\", \"expiry\": \"1week\"}\n",
       "+    params = {\"code\": contents, \"lexer\": \"text\", \"expiry\": \"1week\"}\n",
       "     url = \"https://bpaste.net\"\n",
       "     try:\n",
       "         response = (\n",
       "\n",
       "```\n",
       "\n",
       "### Generated patch\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```diff\n",
       "diff --git a/src/_pytest/pastebin.py b/src/_pytest/pastebin.py\n",
       "index 38ff97f2d..77b4e2621 100644\n",
       "--- a/src/_pytest/pastebin.py\n",
       "+++ b/src/_pytest/pastebin.py\n",
       "@@ -65,7 +65,7 @@ def create_new_paste(contents):\n",
       "     from urllib.request import urlopen\n",
       "     from urllib.parse import urlencode\n",
       " \n",
       "-    params = {\"code\": contents, \"lexer\": \"python3\", \"expiry\": \"1week\"}\n",
       "+    params = {\"code\": contents, \"lexer\": \"text\", \"expiry\": \"1week\"}\n",
       "     url = \"https://bpaste.net\"\n",
       "     try:\n",
       "         response = (\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "swebench.display_patches(data=instance_data, path=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
